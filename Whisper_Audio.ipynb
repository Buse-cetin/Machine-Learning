{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buse-cetin/Machine-Learning/blob/main/Whisper_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Rr1Qg5MwuYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dafb605-87f9-48a1-b5d4-33535ab99812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA L4 (UUID: GPU-2d8a3aaf-3f64-6b8b-c735-e6f90c7e0e00)\n",
            "Mon Apr 22 18:42:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   61C    P0              31W /  72W |  21939MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check gpu type\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vf4cqkCaZn0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0baf6576-8fd7-4943-ab6c-7a0244a80d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-qmqd7g_p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-qmqd7g_p\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.8.1)\n"
          ]
        }
      ],
      "source": [
        "# install libraries\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rC-mpBTgZr3D"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import whisper\n",
        "from whisper.utils import get_writer\n",
        "import os\n",
        "import string\n",
        "from jiwer import wer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9LpaqE6ePPIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f79758-d174-433f-9fc2-0fd06ab75951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "e_fKqCK9OQLE"
      },
      "outputs": [],
      "source": [
        "# Assuming the audio files are in a folder called \"Audio\" under \"Whisper\"\n",
        "audio_folder_path = \"/content/Untitled Folder\"\n",
        "\n",
        "# Assuming the text files will be placed in a folder called \"Transcriptions\" under \"Whisper\"\n",
        "transcription_folder_path = \"/content/drive/MyDrive/Whisper/Transcriptions/\"\n",
        "\n",
        "# Create \"Transcriptions\" folder if does not exist\n",
        "if not os.path.exists(transcription_folder_path):\n",
        "  os.makedirs(transcription_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Lr0_KI8N0mWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f6f5bb-d4d3-4c76-b861-bc6bdbbe5b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Untitled Folder2.mp3\n",
            "/content/Untitled Folder8.mp3\n",
            "/content/Untitled Folder1.mp3\n",
            "/content/Untitled Folder3.mp3\n",
            "/content/Untitled Folder6.mp3\n",
            "/content/Untitled Folder4.mp3\n",
            "/content/Untitled Folder7.mp3\n",
            "/content/Untitled Folder.ipynb_checkpoints\n",
            "/content/Untitled Folder5.mp3\n",
            "\u001b[1m There are 9 audio files to transcribe\n"
          ]
        }
      ],
      "source": [
        "# Get a list of all the file paths in the folder\n",
        "audio_files = []\n",
        "for file in os.listdir(audio_folder_path):\n",
        "    audio_files.append(audio_folder_path + file)\n",
        "for p in audio_files:\n",
        "    print(p)\n",
        "print(f\"\\033[1m There are {len(audio_files)} audio files to transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ToWWQiTv7foY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49316f4-f237-45c9-b885-aac67e842b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m Model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# load whisper model\n",
        "model = whisper.load_model(\"large\")\n",
        "print(f\"\\033[1m Model loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ZG7xbllv_xvO"
      },
      "outputs": [],
      "source": [
        "lang = 'he'\n",
        "output_format = 'all'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "adgPhhduOSyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2e2400-1b00-44fa-b2be-b36235c1c67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Untitled Folder2.mp3\n",
            "/content/Untitled Folder8.mp3\n",
            "/content/Untitled Folder1.mp3\n",
            "/content/Untitled Folder3.mp3\n",
            "/content/Untitled Folder6.mp3\n",
            "/content/Untitled Folder4.mp3\n",
            "/content/Untitled Folder7.mp3\n",
            "/content/Untitled Folder.ipynb_checkpoints\n",
            "/content/Untitled Folder5.mp3\n",
            "\u001b[1m--- Transcribed 9 audio files in 0.0009098052978515625 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# set timer\n",
        "import time\n",
        "start_time = time.time()\n",
        "# transcribe audio files in list\n",
        "for p in audio_files:\n",
        "  #result = model.transcribe(p, verbose = False, language = lang) # to translate add task = 'transalte'\n",
        "  options = {\n",
        "        \"max_line_width\": None,\n",
        "        \"max_line_count\": None,\n",
        "        \"highlight_words\": False\n",
        "    }\n",
        "  # use get_writer method to output files\n",
        "  output_file = get_writer(output_format, transcription_folder_path)\n",
        "  #output_file(result, p[:-4], options=options)\n",
        "  print(p)\n",
        "print(f\"\\033[1m--- Transcribed {len(audio_files)} audio files in %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "sL1NPgEhSONs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d1134b-1941-4b8b-f4c5-fa90b16d326d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# normalize whisper output\n",
        "whisper_output = '/content/drive/MyDrive/Whisper/Transcriptions/Copy of Snyder.txt'\n",
        "whisper_output_norm = open(whisper_output, 'r').read().lower().translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ')\n",
        "print(whisper_output_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "zTOY_r7kUsBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58a3d00-7347-4506-8bb1-590f8ad601b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# normalize ground truth\n",
        "ground_truth = '/content/drive/MyDrive/Whisper/GT/Snyder_GT.txt'\n",
        "ground_truth_norm = open(ground_truth, 'r').read().lower().translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ')\n",
        "print(ground_truth_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "w6mR6ErlVUwD"
      },
      "outputs": [],
      "source": [
        "# calculate WER\n",
        "reference = ground_truth_norm\n",
        "hypothesis = whisper_output_norm\n",
        "error = wer(reference, hypothesis)\n",
        "error_percentage = \"{:.0%}\".format(error)\n",
        "print(error_percentage)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}